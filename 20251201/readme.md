Linux 6.18: [kernel/git/stable/linux.git](https://git.kernel.org/pub/scm/linux/kernel/git/stable/linux.git/tag/?h=v6.18)
Configuration: [here](.config)
Compiler: [gcc](gcc.log)
Reproduction program: [here](repro.c)

---

## Bug Analysis

This bug was discovered through fuzzing testing and was successfully reproduced
on Linux mainline (v6.18). For kernel version, configuration options, reproduction program 
and compiler details, please see the links above.

I analyzed this bug by examining the log generated by the fuzzer. The root
cause should be in the file `fs/hfsplus/extents.c`, specifically involving
the functions `hfsplus_get_block`, `hfsplus_file_extend`, and
`hfsplus_block_allocate`.

### The Problem

The kernel log at the beginning clearly shows the issue: while
`hfsplus_file_extend` already holds the lock, `hfsplus_get_block` attempts
to acquire the same lock again.

```txt
syz.2.6665/56729 is trying to acquire lock:
ffff88803c85bdc8 (&HFSPLUS_I(inode)->extents_lock){+.+.}-{4:4}, at: hfsplus_get_block+0x27d/0xa80 fs/hfsplus/extents.c:260
but task is already holding lock:
ffff88803c85a988 (&HFSPLUS_I(inode)->extents_lock){+.+.}-{4:4}, at: hfsplus_file_extend+0x1be/0x1250 fs/hfsplus/extents.c:453
```

### Call Chain

Here is the relevant portion of the call stack:

```txt
hfsplus_get_block+0x27d/0xa80 fs/hfsplus/extents.c:260
 block_read_full_folio+0x2f4/0x850 fs/buffer.c:2420
 filemap_read_folio+0xbf/0x2a0 mm/filemap.c:2444
 do_read_cache_folio+0x24d/0x590 mm/filemap.c:4036
 do_read_cache_page mm/filemap.c:4102 [inline]
 read_cache_page+0x5d/0x150 mm/filemap.c:4111
 read_mapping_page include/linux/pagemap.h:993 [inline]
 hfsplus_block_allocate+0x131/0xc00 fs/hfsplus/bitmap.c:37
 hfsplus_file_extend+0x439/0x1250 fs/hfsplus/extents.c:464
 hfsplus_get_block+0x1b4/0xa80 fs/hfsplus/extents.c:245
 __block_write_begin_int+0x4e5/0x1660 fs/buffer.c:2145
```

As we can see, `hfsplus_get_block` (at `fs/hfsplus/extents.c:245`) calls
`hfsplus_file_extend` (at `fs/hfsplus/extents.c:464`). Inside
`hfsplus_file_extend`, the lock is acquired, and then `hfsplus_block_allocate`
is called (as shown in the code below):

```c
int hfsplus_file_extend(struct inode *inode, bool zeroout)
{
	...
	mutex_lock(&hip->extents_lock);
	...
	start = hfsplus_block_allocate(sb, sbi->total_blocks, goal, &len);
	...
}
```

While the current thread already holds the lock, `hfsplus_block_allocate`
may invoke `hfsplus_get_block` (at `fs/hfsplus/extents.c:260`). At this point,
`hfsplus_get_block` attempts to acquire the same lock that is already held,
resulting in a recursive locking.

### Attempted Fix

To address this issue, I attempted a simple modification: release the lock
before calling `hfsplus_block_allocate` in `hfsplus_file_extend`, and then
re-acquire it after `hfsplus_block_allocate` returns, as shown below:

```c
int hfsplus_file_extend(struct inode *inode, bool zeroout)
{
	...
	mutex_unlock(&hip->extents_lock);
	len = hip->clump_blocks;
	start = hfsplus_block_allocate(sb, sbi->total_blocks, goal, &len);
	mutex_lock(&hip->extents_lock);
	...
}
```

However, this approach does not work and introduces other similar issues,
as detailed in the [log](fix.log).

### Alternative Approach

Another potential solution would be to change the data structure of
`extents_lock` in `struct hfsplus_inode_info` (e.g., from `struct mutex`
to a reentrant lock like `struct semaphore`). However, this would require
extensive code modifications, which I have not yet attempted.

### Conclusion

The above is my analysis of the bug. I hope it provides some useful insights
for resolving this issue.
